import os
import uuid
import pickle
from datetime import datetime
from typing import List

import cv2
import numpy as np
import face_recognition
from fastapi import UploadFile
from scipy.spatial.distance import cosine

from src.utils.file_io import load_json, save_json
from src.constants import METADATA_PATH, REPRESENTATIVES_PATH, ALBUM_DIR, FACE_DATA_DIR


RECENT_VECTOR_COUNT = 20  # ëŒ€í‘œ ë²¡í„° ê³„ì‚° ì‹œ ì‚¬ìš©í•˜ëŠ” ë²¡í„° ê°œìˆ˜


def generate_filename(original_filename: str) -> str:
    ext = os.path.splitext(original_filename)[-1]
    uid = uuid.uuid4().hex[:8]
    date = datetime.now().strftime("%Y%m%d")
    return f"{date}_{uid}{ext}"


def save_image(file: UploadFile, image_np: np.ndarray, filename: str):
    save_dir = os.path.join(ALBUM_DIR, "uploaded")
    os.makedirs(save_dir, exist_ok=True)
    path = os.path.join(save_dir, filename)
    cv2.imwrite(path, image_np)


# ì¸ë¬¼ë³„ í´ëŸ¬ìŠ¤í„°ë§
async def process_and_classify_faces(files: List[UploadFile]) -> List[dict]:
    metadata = load_json(METADATA_PATH, {})
    representatives = load_json(REPRESENTATIVES_PATH, {})
    override_map = {}

    for face in metadata.values():
        if "override" in face:
            origin = face.get("person_id")
            new = face.get("override")
            if origin != new:  # ìê°€ ì°¸ì¡° ë°©ì§€
                override_map[origin] = new

    if not representatives:
        print("ğŸ“¥ ëŒ€í‘œ ë²¡í„°ê°€ ì—†ìŒ â†’ ì¶œì„ ì²´í¬ìš© ì–¼êµ´ ë¶ˆëŸ¬ì˜¤ê¸°")
        representatives.update(load_attendance_representatives())

    results = []

    for file in files:
        image_bytes = await file.read()
        image_np = np.frombuffer(image_bytes, np.uint8)
        image = cv2.imdecode(image_np, cv2.IMREAD_COLOR)

        # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ ë° ì‚¬ì§„ ì €ì¥
        filename = generate_filename(file.filename)
        save_image(file, image, filename)

        face_locations = face_recognition.face_locations(image)
        encodings = face_recognition.face_encodings(image, face_locations)

        for loc, encoding in zip(face_locations, encodings):
            person_id = find_matching_person_id(encoding, representatives)

            if person_id in override_map:
                original = person_id
                person_id = override_map[person_id]

                # ê¸°ì¡´ ëŒ€í‘œ ë²¡í„° ë° history ì œê±°
                print(f"overrideëœ {original}ì˜ ëŒ€í‘œ ë²¡í„° ì œê±°")
                representatives.pop(original, None)
                representatives.pop(f"{original}_history", None)

            face_id = get_next_face_id(metadata)
            metadata[face_id] = {
                "file_name": filename,
                "location": loc,
                "encoding": encoding.tolist(),
                "person_id": person_id,
            }

            update_representative(person_id, encoding, representatives)

            results.append(
                {
                    "face_id": face_id,
                    "file_name": filename,
                    "location": loc,
                    "person_id": person_id,
                }
            )

    save_json(METADATA_PATH, metadata)
    save_json(REPRESENTATIVES_PATH, representatives)
    return results


def find_matching_person_id(
    new_encoding: np.ndarray, reps: dict, threshold: float = 0.12
) -> str:
    best_match = None
    best_dist = float("inf")

    for person_id, vec in reps.items():
        if person_id.endswith("_history"):
            continue

        vec = np.array(vec, dtype=np.float32).flatten()

        # âœ… ë²¡í„° ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€
        if vec.shape != (128,) or np.any(np.isnan(vec)) or np.any(np.isinf(vec)):
            print(f"ğŸš« {person_id} ëŒ€í‘œ ë²¡í„°ê°€ ì†ìƒë¨. ê±´ë„ˆëœ€.")
            continue

        dist = cosine(new_encoding, vec)

        # âœ… dist ê°’ ìœ íš¨ì„± ê²€ì‚¬
        if np.isnan(dist) or np.isinf(dist):
            print(f"ğŸš« ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ. ê±´ë„ˆëœ€.")
            continue

        print(f"ğŸ§  ë¹„êµ ëŒ€ìƒ {person_id} ë²¡í„°, ê±°ë¦¬: {dist:.4f}")

        if dist < best_dist:
            best_dist = dist
            best_match = person_id

    print(
        f"ğŸ“ ìµœì¢… ê±°ë¦¬: {best_dist:.4f}, ë§¤ì¹­ ëŒ€ìƒ: {best_match} â†’ {'âœ… ê¸°ì¡´ ì¸ë¬¼' if best_dist < threshold else 'ğŸ†• ìƒˆ ì¸ë¬¼'}"
    )

    if best_dist < threshold:
        return best_match
    else:
        print(f"âš ï¸ ìƒˆ ì‚¬ëŒ ìƒì„±ë¨: ê±°ë¦¬ {best_dist:.4f} > threshold {threshold}")
        return get_new_person_id(reps)


# ëŒ€í‘œ ë²¡í„° ê°±ì‹  í•¨ìˆ˜ (ìµœê·¼ Nê°œì˜ ë²¡í„°ë¥¼ í‰ê· )
def update_representative(person_id: str, new_encoding: np.ndarray, reps: dict):
    from collections import deque

    history_key = f"{person_id}_history"
    history = reps.get(history_key, [])
    dq = deque(history, maxlen=RECENT_VECTOR_COUNT)
    dq.append(new_encoding.tolist())

    reps[history_key] = list(dq)

    # medoid ë°©ì‹ìœ¼ë¡œ ëŒ€í‘œ ë²¡í„° ì§€ì •
    rep_vec = get_medoid_vector(dq)
    reps[person_id] = rep_vec


def get_medoid_vector(encoding_list: List[List[float]]) -> List[float]:
    if not encoding_list:
        print("âš ï¸ encoding_list ë¹„ì–´ ìˆìŒ. ë¹ˆ ë²¡í„° ë°˜í™˜.")
        return [0.0] * 128  # fallback

    enc_np = np.array(encoding_list)

    # ê° ë²¡í„° ê°„ ê±°ë¦¬ í–‰ë ¬
    dist_matrix = np.linalg.norm(enc_np[:, None] - enc_np, axis=2)
    dist_sums = np.sum(dist_matrix, axis=1)

    medoid_index = np.argmin(dist_sums)
    return enc_np[medoid_index].tolist()


# ìƒˆë¡œìš´ ì‚¬ëŒ ID ìƒì„±
def get_new_person_id(reps: dict) -> str:
    existing = [
        int(k.replace("person_", ""))
        for k in reps
        if k.startswith("person_") and not k.endswith("_history")
    ]
    next_id = max(existing + [-1]) + 1
    return f"person_{next_id}"


# ì–¼êµ´ ë‹¨ìœ„ ID ìƒì„±
def get_next_face_id(data: dict) -> str:
    existing = [
        int(k.replace("face_", "")) for k in data.keys() if k.startswith("face_")
    ]
    next_id = max(existing + [-1]) + 1
    return f"face_{next_id:04}"


# ì¶œì„ì²´í¬ìš© `.pkl` ì–¼êµ´ ë°ì´í„° â†’ ëŒ€í‘œ ë²¡í„° ë¡œë”© í•¨ìˆ˜
def load_attendance_representatives() -> dict:
    """
    ì¶œì„ ì²´í¬ìš© ì–¼êµ´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í‘œ ë²¡í„°ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•¨
    - person_id ê¸°ì¤€ìœ¼ë¡œ í‰ê·  ë²¡í„°ë¥¼ ê³„ì‚°í•˜ì—¬ ëŒ€í‘œ ë²¡í„°ë¡œ ì‚¬ìš©
    - ìµœê·¼ Nê°œì˜ ë²¡í„°ëŠ” historyë¡œ í•¨ê»˜ ì €ì¥
    """
    reps = {}

    for file in os.listdir(FACE_DATA_DIR):
        if not file.startswith("face_") or not file.endswith(".pkl"):
            continue

        user_id = file.split("_")[1].split(".")[0]
        path = os.path.join(FACE_DATA_DIR, file)

        with open(path, "rb") as f:
            user_data = pickle.load(f)

            # êµ¬ì¡°ê°€ ë¦¬ìŠ¤íŠ¸ë©´ í˜¸í™˜ ì²˜ë¦¬
            encodings = user_data["raw"] if isinstance(user_data, dict) else user_data

            enc_list = encodings[-RECENT_VECTOR_COUNT:]
            mean_vec = np.mean(enc_list, axis=0)

            reps[f"person_{user_id}"] = mean_vec.tolist()
            reps[f"person_{user_id}_history"] = [e.tolist() for e in enc_list]

    return reps
